# SQLite ê¸°ë°˜ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ìµìŠ¤í¬í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

## ê°œìš”

í˜„ì¬ ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ ì‹œìŠ¤í…œì„ SQLite ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ì—¬ ìˆ˜ì–µ ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸‰ì¦ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

## í˜„ì¬ ìƒí™© ë¶„ì„

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¬¸ì œ
- **í˜„ì¬**: `aggregatedStats` êµ¬ì¡°ì²´ê°€ ë””ë ‰í† ë¦¬ë‹¹ ~40KB ë©”ëª¨ë¦¬ ì‚¬ìš©
- **1ì–µ ê°œ íŒŒì¼ ì‹œë‚˜ë¦¬ì˜¤**: ì•½ 404GB ë©”ëª¨ë¦¬ í•„ìš” (ì¹˜ëª…ì )
- **ê·¼ë³¸ ì›ì¸**: ëª¨ë“  ë””ë ‰í† ë¦¬ í†µê³„ë¥¼ ë©”ëª¨ë¦¬ì— ë³´ê´€

### ê¸°ì¡´ ì•„í‚¤í…ì²˜
```
godirwalk â†’ aggregatedStats (ë©”ëª¨ë¦¬) â†’ Prometheus ë©”íŠ¸ë¦­(/metrics API ì‘ë‹µ)
```

### ëª©í‘œ ì•„í‚¤í…ì²˜
```
godirwalk â†’ SQLite ë°ì´í„°ë² ì´ìŠ¤ â†’ Prometheus ë©”íŠ¸ë¦­(/metrics API ì‘ë‹µ)
```

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### Phase 1: ì‚¬ì „ ì¤€ë¹„ ë° ê¸°ë°˜ ì‘ì—…

#### 1.1 ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì½”ë“œ ì œê±° âœ…
- [x] `chunkSize` ê´€ë ¨ ì½”ë“œ ì™„ì „ ì œê±°
- [x] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ
- [x] ì„¤ì • íŒŒì¼ ì •ë¦¬ ì™„ë£Œ

#### 1.2 Git ì²´í¬í¬ì¸íŠ¸ ìƒì„±
```bash
git add .
git commit -m "Phase 1 ì™„ë£Œ: ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì½”ë“œ ì œê±° ë° ì •ë¦¬

- chunkSize ê´€ë ¨ ì½”ë“œ ì™„ì „ ì œê±°
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- ì„¤ì • íŒŒì¼ ì •ë¦¬
ğŸ¤– Generated with [Claude Code](https://claude.ai/code)"
```

### Phase 2: SQLite ìŠ¤í† ë¦¬ì§€ ê³„ì¸µ êµ¬í˜„

#### 2.1 ì˜ì¡´ì„± ì¶”ê°€
```bash
go get github.com/mattn/go-sqlite3
```

#### 2.2 SQLite ìŠ¤í† ë¦¬ì§€ ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„
```go
// storage/interface.go
type Storage interface {
    Initialize() error
    StoreBatch(stats []DiskStat) error
    GetMetricsData(paths map[string]int) ([]DiskStat, error)
    Close() error
    Cleanup() error
}

// storage/sqlite.go
type SQLiteStorage struct {
    db       *sql.DB
    dbPath   string
    batchTx  *sql.Tx
    batchStmt *sql.Stmt
}
```

#### 2.3 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„
```sql
CREATE TABLE IF NOT EXISTS disk_stats (
    path TEXT NOT NULL,
    level INTEGER NOT NULL,
    size INTEGER NOT NULL,
    file_count INTEGER NOT NULL,
    dir_count INTEGER NOT NULL,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (path, level)
);

CREATE INDEX IF NOT EXISTS idx_level ON disk_stats(level);
CREATE INDEX IF NOT EXISTS idx_path_prefix ON disk_stats(path);
CREATE INDEX IF NOT EXISTS idx_size ON disk_stats(size DESC);
```

#### 2.4 ì„±ëŠ¥ ìµœì í™” ì„¤ì •
```go
func (s *SQLiteStorage) optimizeDatabase() error {
    optimizations := []string{
        "PRAGMA journal_mode=WAL",      // ë™ì‹œ ì½ê¸°/ì“°ê¸°
        "PRAGMA synchronous=NORMAL",    // ì„±ëŠ¥ vs ì•ˆì •ì„± ê· í˜•
        "PRAGMA cache_size=10000",      // 10MB ìºì‹œ
        "PRAGMA temp_store=memory",     // ì„ì‹œ í…Œì´ë¸” ë©”ëª¨ë¦¬ ì €ì¥
        "PRAGMA mmap_size=268435456",   // 256MB ë©”ëª¨ë¦¬ ë§µ
    }
    
    for _, pragma := range optimizations {
        if _, err := s.db.Exec(pragma); err != nil {
            return err
        }
    }
    return nil
}
```

### Phase 3: í”„ë¡œì„¸ì„œ ê³„ì¸µ ë¦¬íŒ©í† ë§

#### 3.1 ìƒˆë¡œìš´ í”„ë¡œì„¸ì„œ êµ¬ì¡°
```go
// exporter/processor.go
type processor struct {
    exporter    *Exporter
    storage     Storage
    rootPath    string
    maxLevel    int
    batchBuffer []DiskStat
    batchSize   int
    mu          sync.Mutex
}
```

#### 3.2 ë°°ì¹˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜
```go
func (p *processor) processBatch() error {
    if len(p.batchBuffer) == 0 {
        return nil
    }
    
    // SQLiteì— ë°°ì¹˜ ì €ì¥
    if err := p.storage.StoreBatch(p.batchBuffer); err != nil {
        return err
    }
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬
    p.batchBuffer = p.batchBuffer[:0]
    runtime.GC()
    
    return nil
}
```

#### 3.3 godirwalk ì½œë°± ìˆ˜ì •
```go
func (p *processor) walkCallback(osPathname string, de *godirwalk.Dirent) error {
    // ê¸°ì¡´ í†µê³„ ìˆ˜ì§‘ ë¡œì§
    stat := p.collectStats(osPathname, de)
    
    // ë°°ì¹˜ ë²„í¼ì— ì¶”ê°€
    p.mu.Lock()
    p.batchBuffer = append(p.batchBuffer, stat)
    
    // ë°°ì¹˜ í¬ê¸° ë„ë‹¬ ì‹œ ì²˜ë¦¬
    if len(p.batchBuffer) >= p.batchSize {
        if err := p.processBatch(); err != nil {
            p.mu.Unlock()
            return err
        }
    }
    p.mu.Unlock()
    
    return nil
}
```

### Phase 4: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê³„ì¸µ ìˆ˜ì •

#### 4.1 SQLite ê¸°ë°˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```go
func (e *Exporter) publishMetricsFromStorage() error {
    // SQLiteì—ì„œ ë°ì´í„° ì¡°íšŒ
    stats, err := e.storage.GetMetricsData(e.paths)
    if err != nil {
        return err
    }
    
    // Prometheus ë©”íŠ¸ë¦­ ë°œí–‰
    for _, stat := range stats {
        e.publishSingleMetric(stat)
    }
    
    return nil
}
```

#### 4.2 ì¿¼ë¦¬ ìµœì í™”
```go
func (s *SQLiteStorage) GetMetricsData(paths map[string]int) ([]DiskStat, error) {
    query := `
        SELECT path, level, size, file_count, dir_count 
        FROM disk_stats 
        WHERE level <= ? AND (
    `
    
    var args []interface{}
    var conditions []string
    
    for rootPath, maxLevel := range paths {
        conditions = append(conditions, "path = ? OR path LIKE ?")
        args = append(args, maxLevel, rootPath, rootPath+"/%")
    }
    
    query += strings.Join(conditions, " OR ") + ")"
    
    rows, err := s.db.Query(query, args...)
    // ê²°ê³¼ ì²˜ë¦¬...
}
```

### Phase 5: ì„¤ì • ë° í”Œë˜ê·¸ ìˆ˜ì •

#### 5.1 ì„¤ì • êµ¬ì¡°ì²´ ìˆ˜ì •
```go
type Config struct {
    // ê¸°ì¡´ ì„¤ì •ë“¤...
    
    // SQLite ê´€ë ¨ ì„¤ì •
    DBPath          string `yaml:"db-path"`
    BatchSize       int    `yaml:"batch-size"`
    DBMaxConnections int   `yaml:"db-max-connections"`
    
    // ì œê±°í•  ì„¤ì •
    // DiskCaching     bool   `yaml:"disk-caching"` // ì œê±°
}
```

#### 5.2 CLI í”Œë˜ê·¸ ìˆ˜ì •
```go
// cmd/root.go
func init() {
    // ìƒˆë¡œìš´ í”Œë˜ê·¸
    rootCmd.PersistentFlags().String("db-path", "/tmp/disk-usage.db", "SQLite database path")
    rootCmd.PersistentFlags().Int("batch-size", 1000, "Batch size for database operations")
    
    // ì œê±°í•  í”Œë˜ê·¸
    // rootCmd.PersistentFlags().Bool("disk-caching", false, "Enable disk caching") // ì œê±°
}
```

#### 5.3 ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
```yaml
# config-sqlite.yml
# SQLite ê¸°ë°˜ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ìµìŠ¤í¬í„° ì„¤ì •

# ê¸°ë³¸ ì„¤ì •
analyzed-path: "/srv/nfs/shared/meta-test"
bind-address: "0.0.0.0:9996"
dir-level: 3
mode: "http"
follow-symlinks: false

# SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
db-path: "/tmp/disk-usage.db"
batch-size: 1000
db-max-connections: 1

# ì„±ëŠ¥ ì„¤ì •
max-procs: 12
log-level: "debug"

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì„¤ì •
dir-count: false
file-count: false
size-bucket: true

# ìŠ¤ìº” ì„¤ì • (ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œìš©)
storage-path: "/tmp/disk-usage-cache"
scan-interval-minutes: 60

# ë¬´ì‹œí•  ë””ë ‰í† ë¦¬
ignore-dirs:
  - /proc
  - /dev
  - /sys
  - /run
  - /tmp
```

### Phase 6: ë™ì‹œì„± ë° ì„±ëŠ¥ ìµœì í™”

#### 6.1 ì›Œì»¤ í’€ SQLite í†µí•©
```go
func (e *Exporter) streamingWorker(workerID int, workChan <-chan workUnit, resultChan chan<- workResult, wg *sync.WaitGroup) {
    defer wg.Done()
    
    // ì›Œì»¤ë³„ SQLite ì—°ê²° (ì½ê¸° ì „ìš©)
    storage, err := NewSQLiteStorage(e.dbPath, true) // readOnly = true
    if err != nil {
        log.Errorf("Worker %d: Failed to create storage: %v", workerID, err)
        return
    }
    defer storage.Close()
    
    for work := range workChan {
        processor := newProcessor(e, storage, work.rootPath, work.maxLevel)
        
        // ìŠ¤ìº” ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ë©”ì¸ ìŠ¤í† ë¦¬ì§€ì— ì „ì†¡
        if err := processor.processDirectory(); err != nil {
            resultChan <- workResult{rootPath: work.rootPath, err: err}
            continue
        }
        
        resultChan <- workResult{rootPath: work.rootPath, err: nil}
    }
}
```

#### 6.2 ë°°ì¹˜ ì“°ê¸° ìµœì í™”
```go
func (s *SQLiteStorage) StoreBatch(stats []DiskStat) error {
    tx, err := s.db.Begin()
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    stmt, err := tx.Prepare(`
        INSERT OR REPLACE INTO disk_stats 
        (path, level, size, file_count, dir_count, last_updated) 
        VALUES (?, ?, ?, ?, ?, datetime('now'))
    `)
    if err != nil {
        return err
    }
    defer stmt.Close()
    
    for _, stat := range stats {
        if _, err := stmt.Exec(stat.Path, stat.Level, stat.Size, stat.FileCount, stat.DirCount); err != nil {
            return err
        }
    }
    
    return tx.Commit()
}
```

### Phase 7: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

#### 7.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ìˆ˜ì •
```go
// exporter/sqlite_test.go
func TestSQLiteStorage(t *testing.T) {
    storage := NewSQLiteStorage(":memory:", false)
    defer storage.Close()
    
    // í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    testStats := []DiskStat{
        {Path: "/test", Level: 0, Size: 1000, FileCount: 10},
        {Path: "/test/sub", Level: 1, Size: 500, FileCount: 5},
    }
    
    // ë°°ì¹˜ ì €ì¥ í…ŒìŠ¤íŠ¸
    err := storage.StoreBatch(testStats)
    assert.NoError(t, err)
    
    // ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸
    paths := map[string]int{"/test": 2}
    results, err := storage.GetMetricsData(paths)
    assert.NoError(t, err)
    assert.Len(t, results, 2)
}
```

#### 7.2 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```go
func BenchmarkSQLiteStorage(b *testing.B) {
    storage := NewSQLiteStorage(":memory:", false)
    defer storage.Close()
    
    // ëŒ€ëŸ‰ ë°ì´í„° ìƒì„±
    stats := make([]DiskStat, 10000)
    for i := range stats {
        stats[i] = DiskStat{
            Path: fmt.Sprintf("/test/path/%d", i),
            Level: i % 5,
            Size: int64(i * 1000),
            FileCount: i % 100,
        }
    }
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        storage.StoreBatch(stats)
    }
}
```

#### 7.3 í†µí•© í…ŒìŠ¤íŠ¸
```go
func TestSQLiteMigrationIntegration(t *testing.T) {
    // ì„ì‹œ DB íŒŒì¼ ìƒì„±
    dbPath := "/tmp/test-disk-usage.db"
    defer os.Remove(dbPath)
    
    // SQLite ê¸°ë°˜ ìµìŠ¤í¬í„° ìƒì„±
    pathMap := map[string]int{"/tmp/test-complex": 3}
    exporter := NewExporter(pathMap, false)
    exporter.SetDBPath(dbPath)
    exporter.SetBatchSize(100)
    
    // ìŠ¤ìº” ì‹¤í–‰
    err := exporter.performScan()
    assert.NoError(t, err)
    
    // ë©”íŠ¸ë¦­ ê²€ì¦
    registry := prometheus.NewRegistry()
    registry.MustRegister(diskUsage, diskUsageSizeBucket)
    
    err = exporter.publishMetricsFromStorage()
    assert.NoError(t, err)
    
    metricFamilies, err := registry.Gather()
    assert.NoError(t, err)
    assert.NotEmpty(t, metricFamilies)
}
```

### Phase 8: ë°°í¬ ë° ë§ˆì´ê·¸ë ˆì´ì…˜

#### 8.1 ì„¤ì • íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
```bash
# ê¸°ì¡´ ì„¤ì •ì—ì„œ ì œê±°í•  í•­ëª©ë“¤
# - disk-caching: true
# - chunk-size: 1000

# ìƒˆë¡œ ì¶”ê°€í•  í•­ëª©ë“¤
# + db-path: "/var/lib/disk-usage/data.db"
# + batch-size: 1000
```

#### 8.2 ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
```go
func (e *Exporter) initializeDatabase() error {
    if e.storage == nil {
        storage, err := NewSQLiteStorage(e.dbPath, false)
        if err != nil {
            return fmt.Errorf("failed to initialize SQLite storage: %v", err)
        }
        e.storage = storage
    }
    
    return e.storage.Initialize()
}
```

#### 8.3 ê¸°ì¡´ ìºì‹œ ì •ë¦¬
```go
func (e *Exporter) cleanupLegacyCache() error {
    // ê¸°ì¡´ aggregatedStats ë§µ ì •ë¦¬
    if e.cachedStats != nil {
        e.cachedStats = nil
    }
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬
    runtime.GC()
    
    log.Info("Legacy cache cleaned up successfully")
    return nil
}
```

## ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **í˜„ì¬**: 1ì–µ íŒŒì¼ â†’ ~404GB ë©”ëª¨ë¦¬
- **ê°œì„  í›„**: 1ì–µ íŒŒì¼ â†’ ~100MB ë©”ëª¨ë¦¬ (4000ë°° ê°œì„ )

### ì²˜ë¦¬ ì†ë„
- **ë°°ì¹˜ ì²˜ë¦¬**: 1000ê°œ ë ˆì½”ë“œ ë‹¨ìœ„ë¡œ ì¼ê´„ ì²˜ë¦¬
- **ì¸ë±ìŠ¤ í™œìš©**: path, level ê¸°ë°˜ ë¹ ë¥¸ ê²€ìƒ‰
- **WAL ëª¨ë“œ**: ë™ì‹œ ì½ê¸°/ì“°ê¸° ì„±ëŠ¥ í–¥ìƒ

### í™•ì¥ì„±
- **ë””ìŠ¤í¬ ê¸°ë°˜**: ë©”ëª¨ë¦¬ ì œì•½ ì—†ì´ ë¬´ì œí•œ í™•ì¥
- **ì§€ì†ì„±**: í”„ë¡œì„¸ìŠ¤ ì¬ì‹œì‘ í›„ì—ë„ ë°ì´í„° ìœ ì§€
- **ì¿¼ë¦¬ ìµœì í™”**: SQL ê¸°ë°˜ ë³µì¡í•œ ì§‘ê³„ ì—°ì‚°

## Git ì»¤ë°‹ ì „ëµ

ê° Phaseë³„ë¡œ ì²´í¬í¬ì¸íŠ¸ ìƒì„±:

```bash
# Phase 2 ì™„ë£Œ
git commit -m "Phase 2 ì™„ë£Œ: SQLite ìŠ¤í† ë¦¬ì§€ ê³„ì¸µ êµ¬í˜„

- SQLite ì¸í„°í˜ì´ìŠ¤ ë° êµ¬í˜„ì²´ ì¶”ê°€
- ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„
- ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì ìš©
ğŸ¤– Generated with [Claude Code](https://claude.ai/code)"

# Phase 3 ì™„ë£Œ  
git commit -m "Phase 3 ì™„ë£Œ: í”„ë¡œì„¸ì„œ ê³„ì¸µ ë¦¬íŒ©í† ë§

- ë©”ëª¨ë¦¬ ê¸°ë°˜ ì²˜ë¦¬ë¥¼ SQLite ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë³€ê²½
- godirwalk ì½œë°± SQLite í†µí•©
- ë°°ì¹˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„
ğŸ¤– Generated with [Claude Code](https://claude.ai/code)"

# ìµœì¢… ì™„ë£Œ
git commit -m "SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ

- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 4000ë°° ê°œì„  (404GB â†’ 100MB)
- ìˆ˜ì–µ ê°œ íŒŒì¼ ì²˜ë¦¬ ì§€ì›
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼
ğŸ¤– Generated with [Claude Code](https://claude.ai/code)"
```

## ë‹¤ìŒ ë‹¨ê³„

1. **Phase 1**: ê¸°ë°˜ ì‘ì—… (ì™„ë£Œ) âœ…
2. **Phase 2**: SQLite ìŠ¤í† ë¦¬ì§€ êµ¬í˜„ (ì§„í–‰ ì˜ˆì •)
3. **Phase 3**: í”„ë¡œì„¸ì„œ ë¦¬íŒ©í† ë§
4. **Phase 4**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìˆ˜ì •  
5. **Phase 5**: ì„¤ì • ì—…ë°ì´íŠ¸
6. **Phase 6**: ì„±ëŠ¥ ìµœì í™”
7. **Phase 7**: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
8. **Phase 8**: ë°°í¬ ì¤€ë¹„

ì´ ê³„íšì„ í†µí•´ í˜„ì¬ ë©”ëª¨ë¦¬ ê¸‰ì¦ ë¬¸ì œë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°í•˜ê³ , ìˆ˜ì–µ ê°œ íŒŒì¼ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.